{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 6 - Intro to Deep Learning Image Classification\n",
    "\n",
    "### Due Date: *Wednesday, April 17th*\n",
    "\n",
    "### What to Submit\n",
    "Submit this iPython Notebook--containing all your code for the programming exercises below--on [LearningSuite](https://learningsuite.byu.edu/).\n",
    "\n",
    "Your notebook file should produce the relevant plots and also provide a short write-up with answers to the questions below (at the end of this notebook).\n",
    "\n",
    "Please also fill in here the time that each part took you:\n",
    "1. Part A - Dataset: <span style=\"color:red;\">FILL IN TIME</span>\n",
    "2. Part B - Neural Network Architecture: <span style=\"color:red;\">FILL IN TIME</span>\n",
    "3. Part C - Network Training: <span style=\"color:red;\">FILL IN TIME</span>\n",
    "4. Part D - Testing: <span style=\"color:red;\">FILL IN TIME</span>\n",
    "5. Write-up: <span style=\"color:red;\">FILL IN TIME</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background - Image Classification\n",
    "\n",
    "For this project you will be introduced to the basics of deep learning and the PyTorch framework.  Deep learning can be very computationally expensive and runs fastest with GPU support.  If you do not have access to GPUs on your local machine, you can use some from Google using their [colab tool](https://colab.research.google.com).  Colab runs exactly like jupyter notebooks and you can directly upload your .ipynb file.\n",
    "\n",
    "Image classification is the task of taking an image and labeling it as a category.  Deep learning has been the leading method for image classification since it dominated the [ImageNet competition in 2012](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: Dataset\n",
    "\n",
    "You will be performing classification on the [Stanford Cars Dataset](https://ai.stanford.edu/~jkrause/cars/car_dataset.html), which consists of 16,185 images of 196 classes of cars.  The dataset is split 50-50 into a training set and testing set.  You will want to download each one idividually from Stanford's site or use these links: [Train Set](http://imagenet.stanford.edu/internal/car196/cars_train.tgz) and [Test Set](http://imagenet.stanford.edu/internal/car196/cars_test.tgz).  Each set is around 1 GB of data so please **<span style=\"color:red\">DO NOT</span>** include the files when you upload your notebook--**just turn in the .ipynb file**.  Assume the notebooks will be run with the images in folders labeled `cars_train` and `cars_test` like so:\n",
    "\n",
    "```\n",
    ".\n",
    "+--proj6-image-classification.ipynb\n",
    "+--cars_train\n",
    "|  +--00001.jpg\n",
    "|  +--00002.jpg\n",
    "|  +--...\n",
    "+--cars_test\n",
    "|  +--00001.jpg\n",
    "|  +--00002.jpg\n",
    "|  +--...\n",
    "+--test_annos.json\n",
    "+--train_annos.json\n",
    "```\n",
    "\n",
    "The first step in any deep learning method is to make sure you can read in the data.  Since there will be a lot of images for this project, it is possible not all of them will fit into memory.  This is a common problem in deep learning and PyTorch has provided a pattern so as to only have the images you need in memory at a time.  They provide a class called `DataLoader` that acts as an iterable object.  To use `DataLoader`, you will need to implement a subclass of PyTorches `Dataset` class.  To do you so will need to create a class that inherits from `Dataset` and implements the methods `__getitem__` and `__len__`.  An example is given below and PyTorch provides a [tutorial here](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html):\n",
    "\n",
    "```Python\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super(MyDataset, self).__init__()\n",
    "#         TODO: implement what happens when someone calls: \n",
    "#         dataset = MyDataset()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "#         TODO: implement what happens when someone calls dataset[idx]\n",
    "#         This typically will return an image and its label \n",
    "    \n",
    "    def __len__(self):\n",
    "#         TODO: implement what happens when someone calls len(dataset)\n",
    "\n",
    "dataset = MyDataset()\n",
    "loader = DataLoader(dataset)\n",
    "for im, label in loader:\n",
    "#     TODO: Perform operations\n",
    "```\n",
    "\n",
    "We provide you with two files `test_annos.json` and `train_annos.json`.  These files contain a dictionary mapping image name to the class label the image belongs to.  You can use these files in you Dataset class in order to provide the ground truth labels.  For part A, you will need to implement a dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: Neural Network Architecture\n",
    "\n",
    "The main backbone for deep learning is the actual neural network architecture.  For image classification, this will consist of some combination of `Conv2d` layers with activations--usually `ReLU`--with intermitted downsampling--usually done using `MaxPool2d`--followed by a few Linear layers.  The input to the network should be an image with shape `(batch_size, channels, image_height, image_width)`(e.g. an single image with dimensions 224x224 would be `(1, 3, 224, 224)`) and output a vector of shape `(num_classes,)` where the largest value's index in the output vector indicates the class label.  \n",
    "\n",
    "While we built our own network in the Learning Lab, for this lab we will used one of Pytorch's pretrained networks. This has the benefit of already having learned features from training on an ImageNet classification problem. To pull in this pretrained network, we use the following line of code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv1', 'bn1', 'relu', 'maxpool', 'layer1', 'layer2', 'layer3', 'layer4', 'avgpool', 'fc']\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "print(list(model.__dict__[\"_modules\"].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ResNet18 is a state of the art network that uses convolution layers, batch normalization, layers of residual blocks, and a fully connected layer at the end. The different layers are listed above. However, because the pretrained network was trained on ImageNet, the last layer is designed to predict 1000 classes, not 196 like in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=512, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to use the same architecture as the ResNet, but replace the last fully connected layer with a new fully connected layer that goes from 512 input features to 196 output features.\n",
    "\n",
    "PyTorch provides a nice framework for making a neural network architecture.  A network is typically made as a class that inherits from PyTorch's `Module` class and implments the `forward` method.  A network might take the form of the example below. PyTorch also provides a simple Neural Network [tutorial here](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html), the Training a Classifier tutorial is especially helpful.\n",
    "```Python\n",
    "import torch.nn as nn \n",
    "\n",
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNetwork, self).__init__()\n",
    "#         TODO: setup network here\n",
    "\n",
    "    def forward(self, x):\n",
    "#         TODO: perform the forward pass, which happens when someone calls network(x)\n",
    "```\n",
    "\n",
    "Take all the pretrained layers from ResNet18, but then define your own last fully connected layer. Then write the appropriate forward pass function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C: Training\n",
    "\n",
    "Now that you can access your data and you have a network architecture setup, its time to put things together and start training.  Training requires two major components: 1) the loss function and 2) the optimizer.  The loss function is a comparison between your results and the ground truth data.  The optimizer is what takes the results of the loss function and backpropagates the error to the network weights in an attempt to decrease the loss.  The most common loss functions used for classification is [Cross Entropy](https://pytorch.org/docs/stable/nn.html#crossentropyloss) while the most commonly used optimizer function is [Adam](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam).  \n",
    "\n",
    "A basic training step might take the following form:\n",
    "```Python\n",
    "optimizer.zero_grad()\n",
    "outs = model(inputs)\n",
    "loss = loss_func(outs, labels)  # loss_func would be an instance of a torch.nn.CrossEntropyLoss class\n",
    "loss.backward()\n",
    "optimizer.step()  # optimizer would be an instance of the torch.optim.Adam class\n",
    "```\n",
    "\n",
    "For deliverables on this section, please display a plot of the value of the loss over time.  If things are working, the loss should be decreasing.\n",
    "\n",
    "*note: This step could take several hours so you will want to look into being able to save your model to a file and load it up again*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part D: Testing\n",
    "\n",
    "One of the goals of deep learning is to make a model that generalizes to data it has never seen (e.g. new images of cars).  For this part, you will test your generalizability by running the model on a dataset it has not yet seen during training.  To do so, you will also need to put the model into  you will need to make sure you are not calculating any of the gradients by using `torch.no_grad` in a with statement. You will aslo need to put the network into evaluation mode:\n",
    "```Python\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # enter testing code here\n",
    "```\n",
    "\n",
    "To put the network back into training mode, call `model.train()`.\n",
    "\n",
    "You will also need to compare your actual predictions with the ground truth value for value.  The output of your network, however, will be a vector of length 196 (the number of possible classes for the cars dataset) with the largest value representing the guessed class.  You'll need to extract the guessed class number and compare it with the ground truth number for all images in the test dataset and calculate the overall accuracy.  Print out the overall accuacy your model got. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "Points for this assigment will be assigned as follows (100 points total):\n",
    "* [20 pts] Making a Dataset class\n",
    "* [20 pts] Setting up you architecture\n",
    "* [20 pts] Training your model\n",
    "* [20 pts] Displaying the accuracy of your model\n",
    "\n",
    "The last 20 points are earned through completing a subset of the following explorations:\n",
    "* [10 pts] Enhance your dataloader to include reflection data augmentation (i.e. double the size of your training data by taking the mirror image across the y-axis). **DO NOT** do reflection augmentation across the x-axis (we don't care to detect cars when they are upside down!).\n",
    "* [10 pts] Enhance your dataloader to include random crop data augmentation (i.e. increase the size of your training data by taking a subsection of your image each time). Make sure the crop is not too small, otherwise you might miss parts of the car. \n",
    "* [10 pts] Analyze the effect of learning rates and epochs on the accuracy of the network. Describe what you found and give supporting plots. A list of optimizers in Pytorch can be found [here](https://pytorch.org/docs/stable/optim.html).\n",
    "* [10 pts] Analyze the effect of batch_size and varying optimizers on the accuracy of the network. Describe what you found and give supporting plots. \n",
    "* [10 pts] Analyze the effect of different pretrained networks on the accuracy of the network. Describe what you found and give supporting plots. A list of pretrained networks in Pytorch can be found [here](https://pytorch.org/docs/stable/torchvision/models.html).\n",
    "\n",
    "You may earn up to 10 points extra credit for additional explorations you complete.\n",
    "\n",
    "An additional 15 points of extra credit will be given to the individual with the highest test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
